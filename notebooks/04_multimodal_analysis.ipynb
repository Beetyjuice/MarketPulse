{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Multimodal Analysis - MarketPulse: Real-Time Sentiment & Price Anomaly Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "\n",
    "Ce notebook explore l'analyse multimodale en combinant les donn√©es de prix et de sentiment pour d√©tecter des anomalies et des signaux de trading avanc√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# Configuration de l'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer des donn√©es de sentiment simul√©es\n",
    "def generate_sentiment_data(symbols, start_date, end_date, freq='1D'):\n",
    "    \"\"\"G√©n√©rer des donn√©es de sentiment simul√©es\"\"\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "    \n",
    "    # Cr√©er des donn√©es de sentiment pour chaque symbole\n",
    "    sentiment_data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        for date in date_range:\n",
    "            # G√©n√©rer un score de sentiment avec tendance √† √™tre corr√©l√© avec les mouvements de prix\n",
    "            base_sentiment = random.uniform(-0.5, 0.5)\n",
    "            \n",
    "            # Ajouter une composante al√©atoire mais avec certaines corr√©lations possibles\n",
    "            sentiment_score = base_sentiment + random.uniform(-0.3, 0.3)\n",
    "            sentiment_score = max(-1.0, min(1.0, sentiment_score))  # Limiter √† [-1, 1]\n",
    "            \n",
    "            sentiment_data.append({\n",
    "                'timestamp': date,\n",
    "                'symbol': symbol,\n",
                "                'sentiment_score': sentiment_score,\n",
    "                'sentiment_label': 'positive' if sentiment_score > 0.1 else 'negative' if sentiment_score < -0.1 else 'neutral',\n",
    "                'headline': f'News for {symbol} on {date.strftime(\"%Y-%m-%d\")}'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(sentiment_data)\n",
    "\n",
    "# G√©n√©rer des donn√©es de sentiment\n",
    "symbols = [\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\", \"AMZN\"]\n",
    "sentiment_df = generate_sentiment_data(symbols, '2023-01-01', '2024-12-31')\n",
    "print(f\"Donn√©es de sentiment g√©n√©r√©es: {sentiment_df.shape}\")\n",
    "print(sentiment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©charger les donn√©es de prix\n",
    "price_data = {}\n",
    "for symbol in symbols:\n",
    "    print(f\"T√©l√©chargement des donn√©es de prix pour {symbol}...\")\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(period=\"2y\")\n",
    "    data = data.reset_index()\n",
    "    data['symbol'] = symbol\n",
    "    data = data.rename(columns={'Date': 'timestamp', 'Close': 'price_close'})\n",
    "    \n",
    "    # Calculer les indicateurs techniques\n",
    "    data['rolling_mean'] = data['price_close'].rolling(window=30).mean()\n",
    "    data['rolling_std'] = data['price_close'].rolling(window=30).std()\n",
    "    data['z_score'] = (data['price_close'] - data['rolling_mean']) / data['rolling_std']\n",
    "    data['is_anomaly'] = data['z_score'].abs() > 2.0\n",
    "    data['price_change_pct'] = data['price_close'].pct_change()\n",
    "    \n",
    "    price_data[symbol] = data\n",
    "    print(f\"  - {len(data)} enregistrements t√©l√©charg√©s\")\n",
    "\n",
    "# Combiner toutes les donn√©es de prix\n",
    "all_price_data = pd.concat(price_data.values(), ignore_index=True)\n",
    "print(f\"Donn√©es de prix totales: {all_price_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joindre les donn√©es de prix et de sentiment\n",
    "print(\"Jointure des donn√©es de prix et de sentiment...\")\n",
    "\n",
    "# Convertir les timestamps en date seulement pour la jointure (jour entier)\n",
    "all_price_data['date'] = all_price_data['timestamp'].dt.date\n",
    "sentiment_df['date'] = sentiment_df['timestamp'].dt.date\n",
    "\n",
    "# Joindre les donn√©es sur la date et le symbole\n",
    "merged_data = pd.merge(\n",
    "    all_price_data,\n",
    "    sentiment_df[['date', 'symbol', 'sentiment_score', 'sentiment_label', 'headline']],\n",
    "    on=['date', 'symbol'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Donn√©es fusionn√©es: {merged_data.shape}\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de corr√©lation entre sentiment et prix\n",
    "print(\"Analyse de corr√©lation entre sentiment et prix...\")\n",
    "\n",
    "# Calculer la corr√©lation glissante\n",
    "correlation_data = []\n",
    "for symbol in symbols:\n",
    "    symbol_data = merged_data[merged_data['symbol'] == symbol].copy()\n",
    "    \n",
    "    # Calculer la corr√©lation sur une fen√™tre glissante de 30 jours\n",
    "    rolling_corr = symbol_data.set_index('timestamp')[['sentiment_score', 'price_change_pct']].rolling(window=30).corr()\n",
    "    \n",
    "    # Extraire la corr√©lation prix_change_pct vs sentiment_score\n",
    "    corr_values = []\n",
    "    for i in range(0, len(rolling_corr), 2):  # Chaque paire de lignes\n",
    "        if i+1 < len(rolling_corr):\n",
    "            corr_val = rolling_corr.iloc[i+1]['sentiment_score']\n",
    "            corr_values.append(corr_val)\n",
    "        else:\n",
    "            corr_values.append(np.nan)\n",
    "    \n",
    "    # Ajouter les corr√©lations au dataframe\n",
    "    symbol_data = symbol_data.copy()\n",
    "    symbol_data['sentiment_price_corr'] = corr_values + [np.nan] * (len(symbol_data) - len(corr_values))\n",
    "    \n",
    "    correlation_data.append(symbol_data)\n",
    "\n",
    "correlation_df = pd.concat(correlation_data, ignore_index=True)\n",
    "print(f\"Donn√©es de corr√©lation: {correlation_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©tection d'anomalies multimodales\n",
    "def detect_multimodal_anomalies(df):\n",
    "    \"\"\"D√©tecter les anomalies en combinant les signaux de prix et de sentiment\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Anomalie de prix (d√©j√† calcul√©e)\n",
    "    # Anomalie de sentiment (score extr√™me)\n",
    "    df['is_sentiment_anomaly'] = df['sentiment_score'].abs() > 0.8\n",
    "    \n",
    "    # Anomalie combin√©e : sentiment extr√™me + mouvement de prix important\n",
    "    df['is_multimodal_anomaly'] = (\n",
    "        (df['is_sentiment_anomaly']) & \n",
    "        (df['price_change_pct'].abs() > 0.03)  # Changement de plus de 3%\n",
    "    )\n",
    "    \n",
    "    # Anomalie de divergence : sentiment positif mais prix en baisse (ou l'inverse)\n",
    "    df['is_divergence_anomaly'] = (\n",
    "        ((df['sentiment_score'] > 0.5) & (df['price_change_pct'] < -0.02)) |  # Sentiment positif mais prix baisse\n",
    "        ((df['sentiment_score'] < -0.5) & (df['price_change_pct'] > 0.02))    # Sentiment n√©gatif mais prix monte\n",
    "    )\n",
    "    \n",
    "    # Type d'anomalie\n",
    "    df['anomaly_type'] = 'normal'\n",
    "    df.loc[df['is_multimodal_anomaly'], 'anomaly_type'] = 'multimodal'\n",
    "    df.loc[df['is_divergence_anomaly'], 'anomaly_type'] = 'divergence'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer la d√©tection d'anomalies multimodales\n",
    "anomaly_df = detect_multimodal_anomalies(correlation_df)\n",
    "\n",
    "# Compter les anomalies\n",
    "total_anomalies = len(anomaly_df[anomaly_df['is_multimodal_anomaly'] | anomaly_df['is_divergence_anomaly']])\n",
    "multimodal_anomalies = len(anomaly_df[anomaly_df['is_multimodal_anomaly']])\n",
    "divergence_anomalies = len(anomaly_df[anomaly_df['is_divergence_anomaly']])\n",
    "\n",
    "print(f\"Anomalies totales: {total_anomalies}\")\n",
    "print(f\"Anomalies multimodales: {multimodal_anomalies}\")\n",
    "print(f\"Anomalies de divergence: {divergence_anomalies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les anomalies multimodales pour un symbole\n",
    "symbol = \"AAPL\"\n",
    "symbol_data = anomaly_df[anomaly_df['symbol'] == symbol].copy()\n",
    "\n",
    "# Cr√©er un graphique combin√©\n",
    "fig = go.Figure()\n",
    "\n",
    "# Prix de cl√¥ture\n",
    "fig.add_trace(go.Scatter(x=symbol_data['timestamp'], y=symbol_data['price_close'], \n",
    "                         mode='lines', name='Prix de cl√¥ture', yaxis='y1'))\n",
    "\n",
    "# Score de sentiment\n",
    "fig.add_trace(go.Scatter(x=symbol_data['timestamp'], y=symbol_data['sentiment_score'], \n",
    "                         mode='lines', name='Sentiment', yaxis='y2', line=dict(color='orange')))\n",
    "\n",
    "# Anomalies multimodales\n",
    "multimodal_anomalies = symbol_data[symbol_data['is_multimodal_anomaly']]\n",
    "fig.add_trace(go.Scatter(x=multimodal_anomalies['timestamp'], y=multimodal_anomalies['price_close'], \n",
    "                         mode='markers', name='Anomalies Multimodales', \n",
    "                         marker=dict(color='red', size=10, symbol='x'), yaxis='y1'))\n",
    "\n",
    "# Anomalies de divergence\n",
    "divergence_anomalies = symbol_data[symbol_data['is_divergence_anomaly']]\n",
    "fig.add_trace(go.Scatter(x=divergence_anomalies['timestamp'], y=divergence_anomalies['price_close'], \n",
    "                         mode='markers', name='Anomalies de Divergence', \n",
    "                         marker=dict(color='purple', size=10, symbol='diamond'), yaxis='y1'))\n",
    "\n",
    "# Mise en page\n",
    "fig.update_layout(\n",
    "    title=f'Analyse Multimodale - {symbol} (Prix + Sentiment)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis=dict(title='Prix'),\n",
    "    yaxis2=dict(title='Sentiment', overlaying='y', side='right')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statistique des anomalies\n",
    "print(\"Statistiques des anomalies par symbole:\")\n",
    "\n",
    "stats_data = []\n",
    "for symbol in symbols:\n",
    "    symbol_data = anomaly_df[anomaly_df['symbol'] == symbol]\n",
    "    \n",
    "    total_count = len(symbol_data)\n",
    "    multimodal_count = symbol_data['is_multimodal_anomaly'].sum()\n",
    "    divergence_count = symbol_data['is_divergence_anomaly'].sum()\n",
    "    normal_count = total_count - multimodal_count - divergence_count\n",
    "    \n",
    "    avg_sentiment = symbol_data['sentiment_score'].mean()\n",
    "    avg_price_change = symbol_data['price_change_pct'].mean()\n",
    "    \n",
    "    stats_data.append({\n",
    "        'symbol': symbol,\n",
    "        'total_days': total_count,\n",
    "        'normal_days': normal_count,\n",
    "        'multimodal_anomalies': multimodal_count,\n",
    "        'divergence_anomalies': divergence_count,\n",
    "        'multimodal_rate': multimodal_count / total_count if total_count > 0 else 0,\n",
    "        'divergence_rate': divergence_count / total_count if total_count > 0 else 0,\n",
    "        'avg_sentiment': avg_sentiment,\n",
    "        'avg_price_change': avg_price_change\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "print(stats_df)\n",
    "\n",
    "# Visualiser les taux d'anomalie\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=stats_df['symbol'], y=stats_df['multimodal_rate'], name='Anomalies Multimodales'))\n",
    "fig.add_trace(go.Bar(x=stats_df['symbol'], y=stats_df['divergence_rate'], name='Anomalies de Divergence'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Taux d\\'Anomalies par Symbole',\n",
    "    xaxis_title='Symbole',\n",
    "    yaxis_title='Taux d\\'Anomalie',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un mod√®le simple de signal de trading bas√© sur l'analyse multimodale\n",
    "def generate_trading_signals(df):\n",
    "    \"\"\"G√©n√©rer des signaux de trading bas√©s sur l'analyse multimodale\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Signal d'achat : sentiment positif fort + prix sous-√©valu√© (z-score < -1)\n",
    "    df['buy_signal'] = (\n",
    "        (df['sentiment_score'] > 0.6) & \n",
    "        (df['z_score'] < -1.0) &\n",
    "        (df['sentiment_price_corr'] > 0.3)  # Corr√©lation positive\n",
    "    )\n",
    "    \n",
    "    # Signal de vente : sentiment n√©gatif fort + prix sur√©valu√© (z-score > 1)\n",
    "    df['sell_signal'] = (\n",
    "        (df['sentiment_score'] < -0.6) & \n",
    "        (df['z_score'] > 1.0) &\n",
    "        (df['sentiment_price_corr'] > 0.3)  # Corr√©lation positive\n",
    "    )\n",
    "    \n",
    "    # Signal d'anomalie : divergence entre sentiment et prix\n",
    "    df['anomaly_signal'] = df['is_divergence_anomaly']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer les signaux de trading\n",
    "signals_df = generate_trading_signals(anomaly_df)\n",
    "\n",
    "# Compter les signaux\n",
    "buy_signals = signals_df['buy_signal'].sum()\n",
    "sell_signals = signals_df['sell_signal'].sum()\n",
    "anomaly_signals = signals_df['anomaly_signal'].sum()\n",
    "\n",
    "print(f\"Signaux d'achat: {buy_signals}\")\n",
    "print(f\"Signaux de vente: {sell_signals}\")\n",
    "print(f\"Signaux d'anomalie: {anomaly_signals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les signaux de trading pour un symbole\n",
    "symbol = \"AAPL\"\n",
    "symbol_signals = signals_df[signals_df['symbol'] == symbol].copy()\n",
    "\n",
    "# Cr√©er un graphique avec les signaux\n",
    "fig = go.Figure()\n",
    "\n",
    "# Prix de cl√¥ture\n",
    "fig.add_trace(go.Scatter(x=symbol_signals['timestamp'], y=symbol_signals['price_close'], \n",
    "                         mode='lines', name='Prix de cl√¥ture'))\n",
    "\n",
    "# Signaux d'achat\n",
    "buy_points = symbol_signals[symbol_signals['buy_signal']]\n",
    "fig.add_trace(go.Scatter(x=buy_points['timestamp'], y=buy_points['price_close'], \n",
    "                         mode='markers', name='Signal Achat', \n",
    "                         marker=dict(color='green', size=12, symbol='triangle-up'),\n",
    "                         text='Achat'))\n",
    "\n",
    "# Signaux de vente\n",
    "sell_points = symbol_signals[symbol_signals['sell_signal']]\n",
    "fig.add_trace(go.Scatter(x=sell_points['timestamp'], y=sell_points['price_close'], \n",
    "                         mode='markers', name='Signal Vente', \n",
    "                         marker=dict(color='red', size=12, symbol='triangle-down'),\n",
    "                         text='Vente'))\n",
    "\n",
    "# Anomalies\n",
    "anomaly_points = symbol_signals[symbol_signals['anomaly_signal']]\n",
    "fig.add_trace(go.Scatter(x=anomaly_points['timestamp'], y=anomaly_points['price_close'], \n",
    "                         mode='markers', name='Anomalie', \n",
    "                         marker=dict(color='purple', size=10, symbol='diamond'),\n",
    "                         text='Anomalie'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Signaux de Trading Multimodaux - {symbol}',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Prix',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les r√©sultats pour l'analyse Spark\n",
    "print(\"Sauvegarde des donn√©es d'analyse multimodale...\")\n",
    "\n",
    "# S√©lectionner les colonnes pertinentes pour l'analyse Spark\n",
    "spark_columns = [\",
    "    'timestamp', 'symbol', 'price_close', 'sentiment_score', \n",
    "    'is_multimodal_anomaly', 'is_divergence_anomaly', 'anomaly_type',\n",
    "    'buy_signal', 'sell_signal', 'anomaly_signal'\n",
    "]\n",
    "\n",
    "multimodal_analysis_df = signals_df[spark_columns].copy()\n",
    "multimodal_analysis_df['id'] = range(len(multimodal_analysis_df))  # Ajouter un ID\n",
    "\n",
    "# Sauvegarder au format CSV pour ingestion dans Spark\n",
    "multimodal_analysis_df.to_csv('data/processed/multimodal_analysis.csv', index=False)\n",
    "print(f\"Donn√©es d'analyse multimodale sauvegard√©es: {multimodal_analysis_df.shape}\")\n",
    "\n",
    "# Afficher un aper√ßu\n",
    "print(multimodal_analysis_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a explor√© l'analyse multimodale en combinant les donn√©es de prix et de sentiment. Nous avons:\n",
    "\n",
    "1. Joint les donn√©es de prix et de sentiment\n",
    "2. D√©tect√© des anomalies en combinant les signaux de prix et de sentiment\n",
    "3. Identifi√© des cas de divergence entre sentiment et prix\n",
    "4. G√©n√©r√© des signaux de trading bas√©s sur l'analyse multimodale\n",
    "5. Pr√©par√© les donn√©es pour l'analyse dans Spark\n",
    "\n",
    "Cette approche permet de d√©tecter des situations de march√© complexes qui ne seraient pas visibles avec une seule source de donn√©es, ce qui est essentiel pour un syst√®me de d√©tection d'anomalies en temps r√©el."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}